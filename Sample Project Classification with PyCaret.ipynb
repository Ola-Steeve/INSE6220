{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ola-Steeve/INSE6220/blob/main/Sample%20Project%20Classification%20with%20PyCaret.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Principal Component Analysis**\n",
        "\n",
        "PCA stands for Principal Component Analysis, and it is a widely used technique in data analysis and machine learning for reducing the dimensionality of large datasets. The basic idea behind PCA is to transform a set of high-dimensional variables into a smaller set of uncorrelated variables called principal components, while retaining as much of the original variance as possible."
      ],
      "metadata": {
        "id": "fajFL3-MF9Lv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiyy5Ubf5I1"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N37Pegcf4ft"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "import pandas as pd\n",
        "plt.rcParams['figure.figsize'] = (7,5)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from google.colab import drive"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pandas version: \", pd.__version__)\n",
        "print(\"Seaborn version: \", sns.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa_vh6LG_5sG",
        "outputId": "f4185aab-e0a3-4af4-9074-dd5d8bc7e989"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version:  2.2.2\n",
            "Seaborn version:  0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNo8n9cvP9or"
      },
      "source": [
        "**Dataset**\n",
        "\n",
        "The examined group comprised kernels belonging to three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected for\n",
        "the experiment. High quality visualization of the internal kernel structure was detected using a soft X-ray technique. It is non-destructive and considerably cheaper than other more sophisticated imaging techniques like scanning microscopy or laser technology. The images were recorded on 13x18 cm X-ray KODAK plates. Studies were conducted using combine harvested wheat grain originating from experimental fields, explored at the Institute of Agrophysics of the Polish Academy of Sciences in Lublin.\n",
        "\n",
        "The data set can be used for the tasks of classification and cluster analysis.\n",
        "\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "To construct the data, seven geometric parameters of wheat kernels were measured:\n",
        "1. area A,\n",
        "2. perimeter P,\n",
        "3. compactness C = 4*pi*A/P^2,\n",
        "4. length of kernel,\n",
        "5. width of kernel,\n",
        "6. asymmetry coefficient\n",
        "7. length of kernel groove.\n",
        "All of these parameters were real-valued continuous.\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/seeds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the dataset**\n",
        "\n",
        "**pd.read_csv** is a function in the pandas library in Python that is used to read a CSV (Comma Separated Values) file and convert it into a pandas DataFrame."
      ],
      "metadata": {
        "id": "66CA8nnLSFkc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aN7mI-2e7z1",
        "outputId": "34b9f26e-b724-4650-cef7-54eab5162e25",
        "collapsed": true
      },
      "source": [
        "#read cvs file into dataframe\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive/cicids2017_cleaned.csv\n",
        "df = pd.read_csv('/content/drive/MyDrive/cicids2017_cleaned.csv', low_memory=True)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/cicids2017_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OYopyWLgJs0",
        "collapsed": true
      },
      "source": [
        "# df.info()\n",
        "df.columns[-10:].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of duplicated rows is: \", df.duplicated().sum())"
      ],
      "metadata": {
        "id": "YzdtduQq-Hno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()\n",
        "print(\"After dropping duplicates:\", df.duplicated().sum())\n",
        "print(\"New shape:\", df.shape)\n"
      ],
      "metadata": {
        "id": "Z8FhY73PN5zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'] = df['Attack Type'].astype(str).str.strip()\n",
        "df.loc[df['target'].str.upper().str.contains('BENIGN|NORMAL'), 'target'] = 'Normal'\n",
        "counts = df['target'].value_counts()\n"
      ],
      "metadata": {
        "id": "0toYOtieOx4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of rows with NaNs is: \", df.isna().any(axis=1).sum())"
      ],
      "metadata": {
        "id": "IYHRfG6_99l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'] = df['Attack Type'].astype(str).str.strip()\n",
        "df.loc[df['target'].str.upper().str.contains('BENIGN|NORMAL'), 'target'] = 'Normal'\n",
        "\n",
        "N = 8000  # total rows desired\n",
        "class_weights = df['target'].value_counts(normalize=True)\n",
        "\n",
        "take = (class_weights * N).astype(int).clip(lower=1)\n",
        "\n",
        "df_small = pd.concat([\n",
        "    df[df['target'] == label].sample(\n",
        "        n=min(take[label], len(df[df['target'] == label])),\n",
        "        random_state=42\n",
        "    )\n",
        "    for label in take.index\n",
        "]).reset_index(drop=True)\n",
        "\n",
        "print(df_small['target'].value_counts())\n",
        "print(\"Total rows:\", len(df_small))"
      ],
      "metadata": {
        "id": "KsfBy11FS-Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLS = [\n",
        "    'Destination Port',\n",
        "    'Flow Duration',\n",
        "    'Total Fwd Packets',\n",
        "    'Bwd Packet Length Max',\n",
        "    'Flow IAT Mean'\n",
        "]\n",
        "\n",
        "d = df_small[COLS + ['target']].copy()\n",
        "\n",
        "for c in COLS:\n",
        "    d[c] = np.minimum(d[c], d[c].quantile(0.99))\n",
        "    d[c] = np.clip(d[c], 0, None)\n",
        "    d[c] = np.log1p(d[c])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "d[COLS] = scaler.fit_transform(d[COLS])"
      ],
      "metadata": {
        "id": "fUJ31d4d94mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(\n",
        "    d.sample(800, random_state=42),\n",
        "    vars=COLS, hue='target',\n",
        "    diag_kind='kde',\n",
        "    plot_kws={'s':18, 'alpha':0.55},\n",
        "    diag_kws={'bw_adjust':1.2}\n",
        ")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d1UkNoKjKxYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sns.pairplot** is a function in the seaborn library in Python that is used to plot pairwise relationships between multiple variables in a dataset. The resulting plot is a grid of scatterplots, with each variable plotted against every other variable."
      ],
      "metadata": {
        "id": "NPPbVpljSWRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_initials(name):\n",
        "    tokens = [t for t in name.replace('-', ' ').split() if t.isalpha()]\n",
        "    return ''.join(t[0].upper() for t in tokens)[:4]\n",
        "\n",
        "initials = [make_initials(n) for n in counts.index]\n",
        "legend_map = {make_initials(n): n for n in counts.index}"
      ],
      "metadata": {
        "id": "hI-CiTuFmQkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df_small['target'].value_counts()\n",
        "total_samples = counts.sum()\n",
        "\n",
        "def make_initials(name):\n",
        "    toks = [t for t in name.replace('-', ' ').split() if t.isalpha()]\n",
        "    return ''.join(t[0].upper() for t in toks)[:4]\n",
        "\n",
        "initials = [make_initials(n) for n in counts.index]\n",
        "legend_map = {make_initials(n): n for n in counts.index}\n",
        "\n",
        "# Create legend text WITH percentages\n",
        "legend_lines = []\n",
        "for name, count in counts.items():\n",
        "    init = make_initials(name)\n",
        "    pct = (count / total_samples) * 100\n",
        "    legend_lines.append(f\"{init} = {name} ({pct:.1f}%)\")\n",
        "\n",
        "legend_text = \"\\n\".join(legend_lines)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,5))\n",
        "colors = plt.cm.tab20.colors[:len(initials)]\n",
        "\n",
        "wedges, texts, autotexts = ax.pie(\n",
        "    counts.values,\n",
        "    labels=initials,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    colors=colors,\n",
        "    radius=0.7,\n",
        "    textprops={'fontsize':8}\n",
        ")\n",
        "ax.set_title('Traffic Class Distribution by Attack Type (Initials)', fontsize=11)\n",
        "ax.axis('equal')\n",
        "\n",
        "\n",
        "plt.subplots_adjust(bottom=0.35)\n",
        "\n",
        "plt.figtext(\n",
        "    0.5, 0.02,          # x, y positions\n",
        "    legend_text,\n",
        "    ha='center',\n",
        "    fontsize=9,\n",
        "    va='bottom',\n",
        "    bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", ec=\"gray\", alpha=0.5)\n",
        ")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sJZJWIBaMdbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Matrix**"
      ],
      "metadata": {
        "id": "ZteoxDA_p7Wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['target'], errors='ignore')\n",
        "X.head(10)\n"
      ],
      "metadata": {
        "id": "tGx9oLE7p8ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe().transpose().round(4)\n"
      ],
      "metadata": {
        "id": "fx7KoSGTqGy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standardize the Data**"
      ],
      "metadata": {
        "id": "0pdyJNLGqNBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLS = [\n",
        "    'Destination Port',\n",
        "    'Flow Duration',\n",
        "    'Total Fwd Packets',\n",
        "    'Bwd Packet Length Max',\n",
        "    'Flow IAT Mean'\n",
        "]\n",
        "\n",
        "# Make a small working copy\n",
        "X = df_small[COLS].copy()\n",
        "\n",
        "# Standardize just these\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Put back into a DataFrame with the same column names\n",
        "X = pd.DataFrame(X_scaled, columns=COLS)\n",
        "\n",
        "# Quick check\n",
        "X.head(10).round(4)\n"
      ],
      "metadata": {
        "id": "9BQQk3FlqMcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations and variables**"
      ],
      "metadata": {
        "id": "Yhy56FgdrkK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observations = list(df.index)\n",
        "variables = list(df.columns)"
      ],
      "metadata": {
        "id": "g8UyAR14rmKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Box and Whisker Plots**"
      ],
      "metadata": {
        "id": "_1XtEFRuryrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "ax = sns.boxplot(data=d[COLS], orient=\"v\", palette=\"Set2\")\n",
        "ax.tick_params(axis='x', labelrotation=45)\n",
        "plt.title(\"Boxplot of Selected Network Flow Features (Standardized)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KHBRaWBxrwj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use swarmplot() or stripplot to show the datapoints on top of the boxes:\n",
        "\n",
        "df_melted = d[COLS].melt(var_name='Feature', value_name='Value')\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='Feature', y='Value', data=df_melted, palette='Set2')\n",
        "sns.stripplot(x='Feature', y='Value', data=df_melted, color='black', alpha=0.3, jitter=0.25, size=2)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Boxplot with Strip Overlay: Standardized Network Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RH3Hjb0E1zhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation Matrix**"
      ],
      "metadata": {
        "id": "OweksxIqo8lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap(X.corr(), cmap='RdYlGn_r', linewidths=0.5, annot=True, cbar=False, square=True)\n",
        "plt.yticks(rotation=0)\n",
        "ax.tick_params(labelbottom=False,labeltop=True)\n",
        "ax.tick_params(axis='x', labelrotation=45)\n",
        "ax.tick_params(axis='y', labelrotation=45)"
      ],
      "metadata": {
        "id": "QbrSKCw5n_Cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Applying PCA**"
      ],
      "metadata": {
        "id": "PkWQNwc5w5vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z = PCA(n_components=2).fit_transform(X)\n",
        "y_cat = df_small['target'].astype('category')\n",
        "y = y_cat.cat.codes\n",
        "class_names = list(y_cat.cat.categories)\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "colors = plt.cm.tab20(np.linspace(0,1,len(class_names)))\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    idx = np.where(y == i)\n",
        "    plt.scatter(Z[idx,0], Z[idx,1], s=12, alpha=0.7,\n",
        "                color=colors[i], label=class_name)\n",
        "\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"PCA Projection of CICIDS Features\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TxS1NYxCw8MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eigenvectors**"
      ],
      "metadata": {
        "id": "ClSif7gfxWEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = [\n",
        "    'Destination Port',\n",
        "    'Flow Duration',\n",
        "    'Total Fwd Packets',\n",
        "    'Bwd Packet Length Max',\n",
        "    'Flow IAT Mean'\n",
        "]\n",
        "X_use = df_small[FEATURES].copy()\n",
        "sc = StandardScaler()\n",
        "X_std = sc.fit_transform(X_use)\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "Z = pca.fit_transform(X_std)\n",
        "\n",
        "A = pca.components_.T      # loadings\n",
        "variables = FEATURES\n",
        "A1 = A[:, 0]\n",
        "A2 = A[:, 1]\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.scatter(A1, A2, c='red', s=60, alpha=0.8)\n",
        "\n",
        "plt.xlabel('PC1 Loading')\n",
        "plt.ylabel('PC2 Loading')\n",
        "plt.title('PCA Loading Scatter Plot')\n",
        "\n",
        "for label, x, y in zip(variables, A1, A2):\n",
        "    plt.annotate(\n",
        "        label,\n",
        "        (x, y),\n",
        "        textcoords=\"offset points\",\n",
        "        xytext=(8, 6),\n",
        "        fontsize=9,\n",
        "        ha='left',\n",
        "        va='bottom'\n",
        "    )\n",
        "\n",
        "plt.axhline(0, color='gray', linewidth=0.6)\n",
        "plt.axvline(0, color='gray', linewidth=0.6)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_v5NKnSDxYi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scree plot**"
      ],
      "metadata": {
        "id": "-mPVtK1_xm8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_full = PCA(n_components=None)\n",
        "pca_full.fit(X)\n",
        "Lambda = pca_full.explained_variance_\n",
        "evr    = pca_full.explained_variance_ratio_\n",
        "cum    = evr.cumsum()\n",
        "k = min(20, len(Lambda))\n",
        "x = np.arange(1, k+1)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(x, evr[:k], 'o-', lw=2, label='Individual variance')\n",
        "plt.plot(x, cum[:k], 's--', lw=2, label='Cumulative variance')\n",
        "plt.xticks(x)\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Variance Explained')\n",
        "plt.title('Scree & Cumulative Variance Plot')\n",
        "plt.grid(True, alpha=0.4)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EojyWVKsxofX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explained Variance**"
      ],
      "metadata": {
        "id": "k7uPzSPGx29K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_full = PCA(n_components=None)\n",
        "pca_full.fit(X)   # X = your standardized data\n",
        "ell = pca_full.explained_variance_ratio_\n",
        "ind = np.arange(len(ell))\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(ind, ell, align='center', alpha=0.5, label='Variance per component')\n",
        "plt.plot(np.cumsum(ell), 'r.-', label='Cumulative variance')\n",
        "\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Explained Variance')\n",
        "plt.title('Explained and Cumulative Variance')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "atDa7296x1A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Biplot**"
      ],
      "metadata": {
        "id": "lV63uig-yCHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = [\n",
        "    'Destination Port',\n",
        "    'Flow Duration',\n",
        "    'Total Fwd Packets',\n",
        "    'Bwd Packet Length Max',\n",
        "    'Flow IAT Mean'\n",
        "]\n",
        "\n",
        "X_use = df_small[FEATURES].copy()\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_std = sc.fit_transform(X_use)\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "Z = pca.fit_transform(X_std)           # scores (PC1, PC2)\n",
        "A = pca.components_.T                  # loadings (features Ã— PCs)\n",
        "variables = FEATURES\n",
        "\n",
        "y_cat = df_small['target'].astype('category')\n",
        "y = y_cat.cat.codes\n",
        "class_names = list(y_cat.cat.categories)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "colors = plt.cm.tab20(np.linspace(0, 1, len(class_names)))\n",
        "for i, name in enumerate(class_names):\n",
        "    idx = (y == i)\n",
        "    plt.scatter(Z[idx, 0], Z[idx, 1],\n",
        "                s=10, alpha=0.6,\n",
        "                color=colors[i],\n",
        "                label=name)\n",
        "\n",
        "Z1_max = np.max(np.abs(Z[:, 0]))\n",
        "Z2_max = np.max(np.abs(Z[:, 1]))\n",
        "scale = 0.6\n",
        "\n",
        "for i in range(len(variables)):\n",
        "    A1 = A[i, 0]\n",
        "    A2 = A[i, 1]\n",
        "    plt.arrow(0, 0,\n",
        "              A1 * Z1_max * scale,\n",
        "              A2 * Z2_max * scale,\n",
        "              color='k',\n",
        "              width=0.003,\n",
        "              head_width=0.08,\n",
        "              length_includes_head=True)\n",
        "    plt.text(A1 * Z1_max * scale * 1.1,\n",
        "             A2 * Z2_max * scale * 1.1,\n",
        "             variables[i],\n",
        "             color='k',\n",
        "             fontsize=9)\n",
        "\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('PCA Biplot: CICIDS Features and Attack Classes')\n",
        "plt.axhline(0, color='grey', linewidth=0.5)\n",
        "plt.axvline(0, color='grey', linewidth=0.5)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l8Ylh6OXyDzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using PCA Library**"
      ],
      "metadata": {
        "id": "M4FiOtncuC1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pca"
      ],
      "metadata": {
        "id": "TsSlKTU2uBVf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pca import pca\n",
        "# Initialize and keep all PCs\n",
        "model = pca(n_components=0.85)\n",
        "# Fit transform\n",
        "out = model.fit_transform(X)"
      ],
      "metadata": {
        "id": "nWOLNllFuNmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Principal Components**"
      ],
      "metadata": {
        "id": "1AGXWQMn0CJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out['PC']"
      ],
      "metadata": {
        "id": "M1fufxxQ0FSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scatter plot**"
      ],
      "metadata": {
        "id": "jJhhFoKou_C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.scatter(label=True, legend=False)"
      ],
      "metadata": {
        "id": "m6_jT5z6u76_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eigenvectors**"
      ],
      "metadata": {
        "id": "gzjn82Jsz9CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = out['loadings'].T"
      ],
      "metadata": {
        "id": "KJ_R3CIVz_eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(data=A, x=\"PC1\", y=\"PC2\")\n",
        "plt.xlabel('$A_1$')\n",
        "plt.ylabel('$A_2$')\n",
        "for i in range(A.shape[0]):\n",
        " plt.text(x=A.PC1[i]+0.02,y=A.PC2[i]+0.02, s=variables[i],\n",
        "          fontdict=dict(color='red',size=10),\n",
        "          bbox=dict(facecolor='yellow',alpha=0.5))"
      ],
      "metadata": {
        "id": "xH2ZgdE77PYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scree Plot**"
      ],
      "metadata": {
        "id": "95YUrMZY0L1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VR = out['variance_ratio']\n",
        "x = np.arange(len(VR)) + 1\n",
        "plt.plot(x, VR, 'ro-', lw=3)\n",
        "plt.xticks(x, [\"\"+str(i) for i in x], rotation=0)\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Explained variance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fzXZQSpq0LO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explained Variance Plot**"
      ],
      "metadata": {
        "id": "LpqQ44INuY__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.plot();"
      ],
      "metadata": {
        "id": "LbOzcUrDuX73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Biplot**\n",
        "\n",
        "A biplot is a graphical representation of multivariate data that displays both observations and variables simultaneously in a single plot. Each observation is represented as a point in a two-dimensional plot, while the variables are represented as arrows or vectors that point in the direction of the greatest variation in the data. The length of the vector indicates the magnitude of the variable, while the angle between two vectors reflects their correlation."
      ],
      "metadata": {
        "id": "jlmcDNqhukK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.biplot(label=False, legend=False)"
      ],
      "metadata": {
        "id": "c96LG_bpuhuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTHTUdomQiVs"
      },
      "source": [
        "#**Multiclass Classification with PyCaret**\n",
        "\n",
        "Multiclass classification is a supervised machine learning technique where the goal is to classify instances into one of three or more classes. (Classifying instances into one of two classes is called Binary Classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Splitting**\n",
        "\n",
        "In order to demonstrate the predict_model() function on unseen data, a sample of 21 observations has been withheld from the original dataset to be used for predictions. This should not be confused with a train/test split as this particular split is performed to simulate a real life scenario. Another way to think about this is that these 21 records were not available at the time when the machine learning experiment was performed."
      ],
      "metadata": {
        "id": "f-HJoPz_2a0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.sample(frac=0.9, random_state=786)\n",
        "data_unseen = df.drop(data.index)\n",
        "\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data_unseen.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print('Data for Modeling: ' + str(data.shape))\n",
        "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
      ],
      "metadata": {
        "id": "xKUVrfkZRaN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install PyCaret**\n",
        "\n",
        "PyCaret is an open-source, low-code machine learning library in Python designed to make the end-to-end machine learning process easier and faster for both beginners and experienced data scientists. It offers a variety of tools and functions for data preparation, model training, model selection, and deployment.\n",
        "\n",
        "pip3 install pycaret==2.3.6 is a command used to install a specific version of the PyCaret library in Python. If you encounter an error message, try running the code again."
      ],
      "metadata": {
        "id": "FBO4xllL1XnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # install slim version (default)\n",
        "!pip install pycaret\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2w8Uk0Lr1u8n",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import *\n",
        "\n",
        "# 2. Setup (with your cleaned + capped data)\n",
        "clf = setup(\n",
        "    data=df_small,\n",
        "    target='target',\n",
        "    train_size=0.7,\n",
        "    session_id=123,\n",
        "    normalize=True,\n",
        "    pca=True,\n",
        "    pca_components=0.90\n",
        ")\n",
        "\n",
        "# 3. Compare models\n",
        "best_model = compare_models()\n"
      ],
      "metadata": {
        "id": "37z5Qjs70Yi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up the Environment in PyCaret**\n",
        "\n",
        "The **setup()** function initializes the environment in pycaret and creates the transformation pipeline to prepare the data for modeling and deployment. setup() must be called before executing any other function in pycaret. It takes two mandatory parameters: a pandas dataframe and the name of the target column. All other parameters are optional and are used to customize the pre-processing pipeline.\n",
        "\n",
        "When setup() is executed, PyCaret's inference algorithm will automatically infer the data types for all features based on certain properties. The data type should be inferred correctly but this is not always the case. To account for this, PyCaret displays a table containing the features and their inferred data types after setup() is executed. If all of the data types are correctly identified enter can be pressed to continue or quit can be typed to end the expriment. Ensuring that the data types are correct is of fundamental importance in PyCaret as it automatically performs a few pre-processing tasks which are imperative to any machine learning experiment. These tasks are performed differently for each data type which means it is very important for them to be correctly configured."
      ],
      "metadata": {
        "id": "EDW00xe8uL70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the setup has been succesfully executed it prints the information grid which contains several important pieces of information. Most of the information is related to the pre-processing pipeline which is constructed when setup() is executed. The majority of these features are out of scope for the purposes of this tutorial however a few important things to note at this stage include:\n",
        "\n",
        "* **session_id** : A pseduo-random number distributed as a seed in all functions for later reproducibility. If no session_id is passed, a random number is automatically generated that is distributed to all functions. In this experiment, the session_id is set as 123 for later reproducibility.\n",
        "\n",
        "* **Target Type** : Binary or Multiclass. The Target type is automatically detected and shown. There is no difference in how the experiment is performed for Binary or Multiclass problems. All functionalities are identical.\n",
        "\n",
        "* **Label Encoded** : When the Target variable is of type string (i.e. 'Yes' or 'No') instead of 1 or 0, it automatically encodes the label into 1 and 0 and displays the mapping (0 : No, 1 : Yes) for reference.\n",
        "\n",
        "* **Original Data** : Displays the original shape of the dataset. In this experiment (189, 8) means 189 samples and 8 features including the class column.\n",
        "\n",
        "* **Missing Values** : When there are missing values in the original data this will show as True. For this experiment there are no missing values in the dataset.\n",
        "\n",
        "* **Numeric Features** : The number of features inferred as numeric. In this dataset, 7 out of 8 features are inferred as numeric.\n",
        "\n",
        "* **Categorical Features** : The number of features inferred as categorical. In this dataset, there are no categorical features.\n",
        "\n",
        "* **Transformed Train Set** : Displays the shape of the transformed training set. Notice that the original shape of (189, 8) is transformed into (132, 7) for the transformed train set.\n",
        "\n",
        "* **Transformed Test Set** : Displays the shape of the transformed test/hold-out set. There are 57 samples in test/hold-out set. This split is based on the default value of 70/30 that can be changed using the train_size parameter in setup.\n",
        "\n",
        "Notice how a few tasks that are imperative to perform modeling are automatically handled such as missing value imputation, categorical encoding etc. Most of the parameters in setup() are optional and used for customizing the pre-processing pipeline."
      ],
      "metadata": {
        "id": "iVEB6l8UuoX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing all Machine Learning Models**"
      ],
      "metadata": {
        "id": "j_mMfLGgurlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #show the best model and their statistics\n",
        " best_model = compare_models()"
      ],
      "metadata": {
        "id": "9sGV2r36-CvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "metadata": {
        "id": "kPJ0iHivGAEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a Model**\n",
        "\n",
        "create_model is the most granular function in PyCaret and is often the foundation behind most of the PyCaret functionalities. As the name suggests this function trains and evaluates a model using cross validation that can be set with fold parameter. The output prints a score grid that shows Accuracy, Recall, Precision, F1, Kappa and MCC by fold.\n",
        "\n",
        "For the remaining part of this tutorial, we will work with the below models as our candidate models. The selections are for illustration purposes only and do not necessarily mean they are the top performing or ideal for this type of data.\n",
        "\n",
        "* Decision Tree Classifier ('dt')\n",
        "* K Neighbors Classifier ('knn')\n",
        "* Logistic Regression ('lr')\n",
        "\n",
        "There are many classifiers available in the model library of PyCaret. Please view the create_model() docstring for the list of all available models."
      ],
      "metadata": {
        "id": "nevzuESqnPPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "iIcZPfCAnz3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = create_model('dt')"
      ],
      "metadata": {
        "id": "QT4o4Dc8n55S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trained model object is stored in the variable 'dt'.\n",
        "dt"
      ],
      "metadata": {
        "id": "QYrbeit9n_rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tune a Model:** How to automatically tune the hyper-parameters of a multiclass model. When a model is created using the create_model() function it uses the default hyperparameters. In order to tune hyperparameters, the tune_model() function is used. The tune_model() function is a random grid search of hyperparameters over a pre-defined search space. By default, it is set to optimize Accuracy but this can be changed using optimize parameter. This function automatically tunes the hyperparameters of a model on a pre-defined search space and scores it using stratified cross validation. The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1 and Kappa by fold."
      ],
      "metadata": {
        "id": "QSQfXH47GLW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tune Decision Tree Model**"
      ],
      "metadata": {
        "id": "jlU7JrTXnvsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_dt = tune_model(dt)"
      ],
      "metadata": {
        "id": "Yi1nuM6koOz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tuned model object is stored in the variable 'tuned_dt'.\n",
        "tuned_dt"
      ],
      "metadata": {
        "id": "jBVaJG8_oS-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Decision Tree Model**"
      ],
      "metadata": {
        "id": "lpeE7bCvoW3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to analyze model performance using various plots"
      ],
      "metadata": {
        "id": "tst9M4JLtDBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(tuned_dt)"
      ],
      "metadata": {
        "id": "SCBKV9pNoduC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create K Neighbors Model**"
      ],
      "metadata": {
        "id": "H9yDjeFwpDNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = create_model('knn')"
      ],
      "metadata": {
        "id": "8NjkK6popLk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tune K Neighbors Model**"
      ],
      "metadata": {
        "id": "23nigsjDpPLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_knn = tune_model(knn, custom_grid = {'n_neighbors' : np.arange(0,50,1)})"
      ],
      "metadata": {
        "id": "m_tkSMegpT3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate K Neighbors Model**"
      ],
      "metadata": {
        "id": "UGfMUs53pqfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(tuned_knn)"
      ],
      "metadata": {
        "id": "R78Tf5rVpzjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Logistic Regression Model**"
      ],
      "metadata": {
        "id": "ydk1L2xWq2qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = create_model('lr')"
      ],
      "metadata": {
        "id": "sSTEQEwYrOYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr"
      ],
      "metadata": {
        "id": "lRmL8Eyp4IQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tune Logistic Regression Model**"
      ],
      "metadata": {
        "id": "-yg-5JTYrUV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_lr = tune_model(lr)"
      ],
      "metadata": {
        "id": "_K4dZIG4ratH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Logistic Regression Model**"
      ],
      "metadata": {
        "id": "Abiyi0yurXT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_lr"
      ],
      "metadata": {
        "id": "9p9Gfa1T4Lyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(tuned_lr)"
      ],
      "metadata": {
        "id": "SawqUjx2riff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Random Forest Model**"
      ],
      "metadata": {
        "id": "YpgZ_6E7bYsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = create_model('rf')"
      ],
      "metadata": {
        "id": "Fo8WqmIubegJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tune Random Forest Model**"
      ],
      "metadata": {
        "id": "Sn21eJPvbn9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_rf = tune_model(rf)"
      ],
      "metadata": {
        "id": "zQsPTdp0b0lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Random Forest Model**"
      ],
      "metadata": {
        "id": "XVnYBw-Abvcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(tuned_rf)"
      ],
      "metadata": {
        "id": "AZmoCsITb8Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tune the Best Model**"
      ],
      "metadata": {
        "id": "AOFarRsjnqRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune hyperparameters with scikit-learn (default)\n",
        "tuned_best_model = tune_model(best_model)"
      ],
      "metadata": {
        "id": "Vh-VH70HF6Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_best_model"
      ],
      "metadata": {
        "id": "hhAXhrLQGUq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Best Model**\n",
        "\n",
        "One way to analyze the performance of models is to use the evaluate_model() function which displays a user interface for all of the available plots for a given model. It internally uses the plot_model() function."
      ],
      "metadata": {
        "id": "fALnq3BVmznf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(tuned_best_model)"
      ],
      "metadata": {
        "id": "p4r6dhok_TLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Classification + PCA**"
      ],
      "metadata": {
        "id": "4TyjzFB2yQnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pca = setup(data=df, target='class', train_size=0.7, session_id=123, normalize = True, pca = True, pca_components = 3)"
      ],
      "metadata": {
        "id": "foTqKReZyXrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show the best model and their statistics\n",
        "best_model_pca = compare_models()"
      ],
      "metadata": {
        "id": "QKMihhxFzPeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_pca"
      ],
      "metadata": {
        "id": "skrf2RvczmgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tune the Best Model**"
      ],
      "metadata": {
        "id": "AZKuTqMWayqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune hyperparameters with scikit-learn (default)\n",
        "tuned_best_model_pca = tune_model(best_model_pca)"
      ],
      "metadata": {
        "id": "vNFJizzAzF4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_best_model_pca"
      ],
      "metadata": {
        "id": "01YswRZ_SnDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Best Model**\n",
        "\n",
        "One way to analyze the performance of models is to use the evaluate_model() function which displays a user interface for all of the available plots for a given model. It internally uses the plot_model() function."
      ],
      "metadata": {
        "id": "ypTlvmEjbP_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(tuned_best_model_pca)"
      ],
      "metadata": {
        "id": "9QjMjiGhz5XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The AUC metric is not available for Multiclass classification however the column will still be shown with zero values to maintain consistency between the Binary Classification and Multiclass Classification display grids."
      ],
      "metadata": {
        "id": "Ivt9unVvmXbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " rf_pca = create_model('rf')"
      ],
      "metadata": {
        "id": "aBhXzsWjeEPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_rf_pca = tune_model(rf_pca)"
      ],
      "metadata": {
        "id": "rjM4X8-teNeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Explainable AI with Shapley values**\n",
        "\n",
        "Shapley values are a widely used approach from cooperative game theory that come with desirable properties."
      ],
      "metadata": {
        "id": "K6V2L9F7d_D1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Analysis Extras for Explainable AI**"
      ],
      "metadata": {
        "id": "JGNbgSYnIHKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret[analysis]"
      ],
      "metadata": {
        "id": "oemBApPBIYCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHAP Summary Plot**\n",
        "\n",
        "Rather than using a typical feature importance bar chart, we use a density scatter plot of SHAP values for each feature to identify how much impact each feature has on the model output for individuals in the validation dataset. Features are sorted by the sum of the SHAP value magnitudes across all samples."
      ],
      "metadata": {
        "id": "Wnaul13dd2j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpret_model(tuned_rf_pca, plot='summary')"
      ],
      "metadata": {
        "id": "7U78G1jdaBpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explainer = shap.TreeExplainer(tuned_rf_pca)\n",
        "#X = df.drop('class', axis=1)\n",
        "#shap_values = explainer.shap_values(X)\n",
        "#shap.summary_plot(shap_values, X)"
      ],
      "metadata": {
        "id": "-Zvm47ptdDJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize a single prediction**"
      ],
      "metadata": {
        "id": "roz4ulv6j9Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpret_model(tuned_rf_pca, plot='reason', observation=32)"
      ],
      "metadata": {
        "id": "4UJFIC1FhwCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above the plot, we can see the \"base value,\" which is defined as the mean predicted target; and f(x), which is the prediction for a selected observation (i.e. observation number 32). The red-colored features increased the predicted value, while the blue-colored features decreased it. The size of each feature (i.e. Principal Component) indicates the impact it has on the model."
      ],
      "metadata": {
        "id": "w5ilsHn9jL0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize many predictions**"
      ],
      "metadata": {
        "id": "s4N6KhhtkLyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpret_model(tuned_rf_pca, plot='reason')"
      ],
      "metadata": {
        "id": "u1qd7cYDkQ5B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}